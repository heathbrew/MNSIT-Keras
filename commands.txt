# Professional Documentation: Managing Data and Version Control for ML Projects

This documentation outlines best practices and command-line instructions for managing datasets, version control, and document conversion within the context of Machine Learning (ML) projects. It is designed to assist data scientists and engineers in efficiently handling large datasets, maintaining code versioning, and converting documents for reporting or presentation purposes.

## Dataset Management

### Compressing and Archiving Datasets

To compress and archive datasets, particularly to optimize storage space or prepare for data sharing, use the `Compress-Archive` PowerShell command:

```powershell
Compress-Archive -Path "Dataset\Unzipped data" -DestinationPath "Dataset\Zipped data\Mnist.zip"
```

This command compresses the folder "Dataset\Unzipped data" into a zip file located at "Dataset\Zipped data\Mnist.zip", facilitating easier distribution or backup of data.

## Version Control with Git

### Configuring Git for Large Files

Projects involving large datasets or binary files can exceed the default limitations of Git. To accommodate large files, increase the `http.postBuffer` size and utilize Git Large File Storage (LFS).

#### Increase HTTP Post Buffer

```bash
git config --global http.postBuffer 524288000
```

This command increases the Git HTTP post buffer size to 500 MB, helping to prevent errors when pushing large files.

#### Resetting Git Repository

To undo recent commits and prepare the repository for large file handling:

```bash
git reset
```

### Handling Large Files with Git LFS

Install Git LFS and track large files to efficiently manage them without bloating the repository.

#### Install Git LFS

```bash
git lfs install
```

#### Track Large Files

```bash
git lfs track "Dataset/Modeltraining/X_test.csv"
git lfs track "Dataset/Modeltraining/X_train.csv"
git lfs track "Dataset/Unzipped data/mnist_784.arff"
```

These commands configure Git LFS to track the specified large files, ensuring they are handled separately from the rest of the repository.

### Removing Files from Git Cache

To remove files from the staging area and index (while keeping local copies), use the `git rm --cached` command:

```bash
git rm --cached Dataset/Modeltraining/X_test.csv
git rm --cached Dataset/Modeltraining/X_train.csv
git rm --cached Dataset/Unzipped data/mnist_784.arff
```

To unstage all tracked files but keep them in your filesystem:

```bash
git rm -r --cached .
```

## Document Conversion

### Installing Required Packages

For converting Jupyter notebooks to PDFs or reducing PDF file size, install the necessary packages:

```bash
sudo apt-get update
sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic pandoc
sudo apt install ghostscript
```

### Converting Jupyter Notebooks to PDF

```bash
jupyter nbconvert --to pdf 06_model_Experiments.ipynb
jupyter nbconvert --to pdf 07_model_evaluation.ipynb
```

These commands convert the specified Jupyter notebooks to PDF format, suitable for reporting or documentation purposes.

### Compressing PDF Files

For compressing PDF files to reduce their file size (while maintaining readability):

```bash
gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/screen -dNOPAUSE -dQUIET -dBATCH -sOutputFile=compressed_output.pdf original.pdf
```

Replace `original.pdf` with the name of your PDF file and `compressed_output.pdf` with the desired output file name.

This documentation provides a comprehensive guide to managing datasets, version control, and document conversion within ML projects. By following these practices, teams can ensure efficient data handling, maintain code integrity, and produce high-quality documentation.
